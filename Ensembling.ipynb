{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load OOF predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(233234,)\n",
      "(233234,)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import glob\n",
    "\n",
    "# cat_model_paths = glob.glob('models/catboost_iso_*_10_et_v4_1.41421356237-random-false_15s_cfg3_seed*_v2_r1-10_aug_gaw033_drop/0.p')\n",
    "# cat_model_paths = glob.glob('models/catboost_iso_*_10_et_v4_0.6-random-true_15s_cfg3_seed*_v2_r1-10_aug_gaw033_drop/0.p')\n",
    "cat_model_paths = glob.glob('models/catboost_iso_*_10_et_v6_w25_0.6-random-true_15s_cfg3_seed*_v2_r1-10_aug_gaw033_reann_drop/0.p')\n",
    "cat_models = [joblib.load(p) for p in cat_model_paths]\n",
    "print(len(cat_models))\n",
    "print(cat_models[0]['base_oof_preds'].shape)\n",
    "print(cat_models[0]['isotonic_oof_preds'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(233234,)\n",
      "(233234,)\n"
     ]
    }
   ],
   "source": [
    "# lgbm_model_paths = glob.glob('models/lgbm_iso_*_10_et_v4_1.41421356237-random-false_15s_cfg4_seed*_r1-10_aug_gaw33/0.p')\n",
    "# lgbm_model_paths = glob.glob('models/lgbm_iso_*_10_et_v4_0.6-random-true_15s_cfg5_seed*_r1-10_aug_gaw33_drop/0.p')\n",
    "# lgbm_model_paths = glob.glob('models/lgbm_iso_*_10_et_v6_w100_0.6-random-true_15s_cfg5_seed*_r1-10_aug_gaw33_reann-v2_drop/0.p')\n",
    "lgbm_model_paths = glob.glob('models/lgbm_iso_*_10_et_v6_w100_0.6-random-true_15s_cfg5_seed*_r1-10_aug_gaw33_drop/0.p')\n",
    "lgbm_models = [joblib.load(p) for p in lgbm_model_paths]\n",
    "print(len(lgbm_models))\n",
    "print(lgbm_models[0]['base_oof_preds'].shape)\n",
    "print(lgbm_models[0]['isotonic_oof_preds'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(233234,)\n",
      "(233234,)\n"
     ]
    }
   ],
   "source": [
    "# tabm_model_paths = glob.glob('models/tabm_iso_*_10_et_v4_141421356237-random-false_15s_cfg2_seed*_r1-10_gaw0330/0.pkl')\n",
    "# tabm_model_paths = glob.glob('models/tabm_iso_*_10_et_v4_06-random-true_15s_cfg8_seed*_r1-10_gaw0330_drop/0.pkl')\n",
    "tabm_model_paths = glob.glob('models/tabm_iso_*_10_et_v6_w50_06-random-true_15s_cfg8_seed*_r1-10_gaw0330_reann_drop/0.pkl')\n",
    "tabm_models = [joblib.load(p) for p in tabm_model_paths]\n",
    "print(len(tabm_models))\n",
    "print(tabm_models[0]['base_oof_preds'].shape)\n",
    "print(tabm_models[0]['isotonic_oof_preds'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "train_test_df = pl.read_csv('/mnt/data01/data/TreeSearch/data/from_organizers/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_test_df['utility_agent1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check baseline scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36862095108952814 0.3649665122763637\n",
      "0.3643488846308908 0.3597684352642133\n",
      "0.3653660952363526 0.36144343638540893\n",
      "\n",
      "Mean base rmse 0.3661119769855905\n",
      "Mean iso rmse 0.362059461308662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "base_rmses = []\n",
    "iso_rmses = []\n",
    "for cat_model in cat_models:\n",
    "    base_rmse = root_mean_squared_error(y, cat_model['base_oof_preds'])\n",
    "    iso_rmse = root_mean_squared_error(y, cat_model['isotonic_oof_preds'])\n",
    "\n",
    "    base_rmses.append(base_rmse)\n",
    "    iso_rmses.append(iso_rmse)\n",
    "    print(base_rmse, iso_rmse)\n",
    "\n",
    "print('\\nMean base rmse', sum(base_rmses) / len(base_rmses))\n",
    "print('Mean iso rmse', sum(iso_rmses) / len(iso_rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36094447492375115 0.35848623038505045\n",
      "0.3604770595085328 0.35790418918621636\n",
      "0.35847736444768297 0.3560676571862704\n",
      "\n",
      "Mean base rmse 0.35996629962665566\n",
      "Mean iso rmse 0.3574860255858458\n"
     ]
    }
   ],
   "source": [
    "base_rmses = []\n",
    "iso_rmses = []\n",
    "for lgbm_model in lgbm_models:\n",
    "    base_rmse = root_mean_squared_error(y, lgbm_model['base_oof_preds'])\n",
    "    iso_rmse = root_mean_squared_error(y, lgbm_model['isotonic_oof_preds'])\n",
    "\n",
    "    base_rmses.append(base_rmse)\n",
    "    iso_rmses.append(iso_rmse)\n",
    "    print(base_rmse, iso_rmse)\n",
    "\n",
    "print('\\nMean base rmse', sum(base_rmses) / len(base_rmses))\n",
    "print('Mean iso rmse', sum(iso_rmses) / len(iso_rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3491910888647715 0.3495742284538155\n",
      "0.3526643163568214 0.3526390878483679\n",
      "0.35285656925430026 0.35310747571379214\n",
      "\n",
      "Mean base rmse 0.35157065815863103\n",
      "Mean iso rmse 0.3517735973386585\n"
     ]
    }
   ],
   "source": [
    "base_rmses = []\n",
    "iso_rmses = []\n",
    "for tabm_model in tabm_models:\n",
    "    base_rmse = root_mean_squared_error(y, tabm_model['base_oof_preds'])\n",
    "    iso_rmse = root_mean_squared_error(y, tabm_model['isotonic_oof_preds'])\n",
    "\n",
    "    base_rmses.append(base_rmse)\n",
    "    iso_rmses.append(iso_rmse)\n",
    "    print(base_rmse, iso_rmse)\n",
    "\n",
    "print('\\nMean base rmse', sum(base_rmses) / len(base_rmses))\n",
    "print('Mean iso rmse', sum(iso_rmses) / len(iso_rmses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine optimal isotonic weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11323483 0.89372672] 0.3649323894717554\n",
      "[0.10179036 0.90530423] 0.3597374335982144\n",
      "[0.09914129 0.90726852] 0.36141769186780015\n",
      "\n",
      "Mean residual weight: 0.10472216078836316\n",
      "Mean RMSE: 0.36202917164592324\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "def GetOptimalWeights(y_true, y_preds1, y_preds2):\n",
    "    def loss_func(weights):\n",
    "        return root_mean_squared_error(y_true, weights[0] * y_preds1 + weights[1] * y_preds2)\n",
    "    weights = minimize(loss_func, [0.5, 0.5], method='Nelder-Mead')\n",
    "    return weights.x\n",
    "\n",
    "cat_residual_weights = []\n",
    "cat_merged_rmses = []\n",
    "for cat_model in cat_models:\n",
    "    weights = GetOptimalWeights(y, cat_model['base_oof_preds'], cat_model['isotonic_oof_preds'])\n",
    "    merged_cat_preds = weights[0] * cat_model['base_oof_preds'] + weights[1] * cat_model['isotonic_oof_preds']\n",
    "\n",
    "    merged_rmse = root_mean_squared_error(y, merged_cat_preds)\n",
    "    print(weights, merged_rmse)\n",
    "\n",
    "    cat_residual_weights.append(weights[0])\n",
    "    cat_merged_rmses.append(merged_rmse)\n",
    "\n",
    "print('\\nMean residual weight:', np.mean(cat_residual_weights))\n",
    "print('Mean RMSE:', np.mean(cat_merged_rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12983063 0.87616893] 0.35845127584427733\n",
      "[0.1482264  0.85836758] 0.3578545230175841\n",
      "[0.1920827  0.81772238] 0.35599119581955846\n",
      "\n",
      "Mean residual weight: 0.15671324329865707\n",
      "Mean RMSE: 0.35743233156047327\n"
     ]
    }
   ],
   "source": [
    "lgbm_residual_weights = []\n",
    "lgbm_merged_rmses = []\n",
    "for lgbm_model in lgbm_models:\n",
    "    weights = GetOptimalWeights(y, lgbm_model['base_oof_preds'], lgbm_model['isotonic_oof_preds'])\n",
    "    merged_lgbm_preds = weights[0] * lgbm_model['base_oof_preds'] + weights[1] * lgbm_model['isotonic_oof_preds']\n",
    "\n",
    "    merged_rmse = root_mean_squared_error(y, merged_lgbm_preds)\n",
    "    print(weights, merged_rmse)\n",
    "\n",
    "    lgbm_residual_weights.append(weights[0])\n",
    "    lgbm_merged_rmses.append(merged_rmse)\n",
    "\n",
    "print('\\nMean residual weight:', np.mean(lgbm_residual_weights))\n",
    "print('Mean RMSE:', np.mean(lgbm_merged_rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.25818341 -0.27984265] 0.3490518315107495\n",
      "[0.67938267 0.30640674] 0.3524595600126872\n",
      "[ 1.47655891 -0.51602212] 0.3525155686301919\n",
      "\n",
      "Mean residual weight: 1.1380416626933936\n",
      "Mean RMSE: 0.3513423200512095\n"
     ]
    }
   ],
   "source": [
    "tabm_residual_weights = []\n",
    "tabm_merged_rmses = []\n",
    "for tabm_model in tabm_models:\n",
    "    weights = GetOptimalWeights(y, tabm_model['base_oof_preds'], tabm_model['isotonic_oof_preds'])\n",
    "    merged_tabm_preds = weights[0] * tabm_model['base_oof_preds'] + weights[1] * tabm_model['isotonic_oof_preds']\n",
    "    # merged_tabm_preds = 0.97 * tabm_model['base_oof_preds'] + 0.03 * tabm_model['isotonic_oof_preds']\n",
    "    # merged_tabm_preds += np.random.normal(0, 0.105, merged_tabm_preds.shape)\n",
    "\n",
    "    merged_rmse = root_mean_squared_error(y, merged_tabm_preds)\n",
    "    print(weights, merged_rmse)\n",
    "\n",
    "    tabm_residual_weights.append(weights[0])\n",
    "    tabm_merged_rmses.append(merged_rmse)\n",
    "\n",
    "print('\\nMean residual weight:', np.mean(tabm_residual_weights))\n",
    "print('Mean RMSE:', np.mean(tabm_merged_rmses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine optimal cat vs. LGBM weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29227175 0.72360044] 0.3572084094211941\n",
      "[0.47065085 0.55289338] 0.3530765604555505\n",
      "[0.38439281 0.6374224 ] 0.3529554850923837\n",
      "\n",
      "Mean cat weight: 0.382438471940547\n",
      "Mean RMSE: 0.3544134849897094\n"
     ]
    }
   ],
   "source": [
    "cat_weights = []\n",
    "ensemble_rmses = []\n",
    "for cat_model, lgbm_model in zip(cat_models, lgbm_models):\n",
    "    # cat_residual_weight = 0.12\n",
    "    cat_residual_weight = 0.14\n",
    "    merged_cat_preds = cat_residual_weight * cat_model['base_oof_preds'] + (1 - cat_residual_weight) * cat_model['isotonic_oof_preds']\n",
    "\n",
    "    # lgbm_residual_weight = 0.16\n",
    "    lgbm_residual_weight = 0.14\n",
    "    merged_lgbm_preds = lgbm_residual_weight * lgbm_model['base_oof_preds'] + (1 - lgbm_residual_weight) * lgbm_model['isotonic_oof_preds']\n",
    "\n",
    "    weights = GetOptimalWeights(y, merged_cat_preds, merged_lgbm_preds)\n",
    "    merged_preds = weights[0] * merged_cat_preds + weights[1] * merged_lgbm_preds\n",
    "\n",
    "    merged_rmse = root_mean_squared_error(y, merged_preds)\n",
    "\n",
    "    print(weights, merged_rmse)\n",
    "\n",
    "    cat_weights.append(weights[0])\n",
    "    ensemble_rmses.append(merged_rmse)\n",
    "\n",
    "print('\\nMean cat weight:', np.mean(cat_weights))\n",
    "print('Mean RMSE:', np.mean(ensemble_rmses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine optimal 3-way ensemble weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31778217 0.06400233 0.63163647] 0.3447577587290351\n",
      "[0.27097535 0.23853281 0.5091408 ] 0.3458766815428262\n",
      "[0.39890472 0.10148923 0.51357002] 0.34569282814707714\n",
      "\n",
      "Mean weights: [0.32922075 0.13467479 0.5514491 ]\n",
      "Mean RMSE: 0.3454424228063128\n"
     ]
    }
   ],
   "source": [
    "def GetOptimalWeightsX3(y_true, y_preds1, y_preds2, preds_3):\n",
    "    def loss_func(weights):\n",
    "        return root_mean_squared_error(y_true, weights[0] * y_preds1 + weights[1] * y_preds2 + weights[2] * preds_3)\n",
    "    weights = minimize(loss_func, [0.5, 0.5, 0.5], method='Nelder-Mead')\n",
    "    return weights.x\n",
    "\n",
    "all_weights = []\n",
    "ensemble_rmses = []\n",
    "for cat_model, lgbm_model, tabm_model in zip(cat_models, lgbm_models, tabm_models):\n",
    "    # cat_residual_weight = 0.12\n",
    "    # lgbm_residual_weight = 0.16\n",
    "    # tabm_residual_weight = 0.97\n",
    "\n",
    "    cat_residual_weight = 0.105\n",
    "    lgbm_residual_weight = 0.137\n",
    "    tabm_residual_weight = 0.98\n",
    "    \n",
    "    merged_lgbm_preds = lgbm_residual_weight * lgbm_model['base_oof_preds'] + (1 - lgbm_residual_weight) * lgbm_model['isotonic_oof_preds']\n",
    "    merged_cat_preds = cat_residual_weight * cat_model['base_oof_preds'] + (1 - cat_residual_weight) * cat_model['isotonic_oof_preds']\n",
    "    merged_tabm_preds = tabm_residual_weight * tabm_model['base_oof_preds'] + (1 - tabm_residual_weight) * tabm_model['isotonic_oof_preds']\n",
    "    # merged_tabm_preds += np.random.normal(0, 0.105, size=y.shape[0])\n",
    "\n",
    "    weights = GetOptimalWeightsX3(y, merged_lgbm_preds, merged_cat_preds, merged_tabm_preds)\n",
    "    merged_preds = weights[0] * merged_lgbm_preds + weights[1] * merged_cat_preds + weights[2] * merged_tabm_preds\n",
    "\n",
    "    merged_rmse = root_mean_squared_error(y, merged_preds)\n",
    "\n",
    "    print(weights, merged_rmse)\n",
    "\n",
    "    all_weights.append(weights)\n",
    "    ensemble_rmses.append(merged_rmse)\n",
    "\n",
    "print('\\nMean weights:', np.mean(all_weights, axis=0))\n",
    "print('Mean RMSE:', np.mean(ensemble_rmses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure overall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35406452800704635\n",
      "0.35018122735515594\n",
      "0.3511747063906921\n",
      "\n",
      "Mean RMSE: 0.35180682058429813\n"
     ]
    }
   ],
   "source": [
    "ensemble_rmses = []\n",
    "for cat_model, lgbm_model in zip(cat_models, lgbm_models):\n",
    "    cat_residual_weight = 0.12\n",
    "    merged_cat_preds = cat_residual_weight * cat_model['base_oof_preds'] + (1 - cat_residual_weight) * cat_model['isotonic_oof_preds']\n",
    "\n",
    "    lgbm_residual_weight = 0.16\n",
    "    merged_lgbm_preds = lgbm_residual_weight * lgbm_model['base_oof_preds'] + (1 - lgbm_residual_weight) * lgbm_model['isotonic_oof_preds']\n",
    "\n",
    "    tabm_residual_weight = 0.97\n",
    "    merged_tabm_preds = tabm_residual_weight * tabm_model['base_oof_preds'] + (1 - tabm_residual_weight) * tabm_model['isotonic_oof_preds']\n",
    "    # merged_tabm_preds += np.random.normal(0, 0.105, size=y.shape[0])\n",
    "\n",
    "    # weights = [4, 2, 1] # 0.35544357913564156\n",
    "    weights = [4, 1.5, 1.2]\n",
    "    merged_preds = ((weights[0] * merged_cat_preds) + (weights[1] * merged_lgbm_preds) + (weights[2] * merged_tabm_preds))/sum(weights)\n",
    "\n",
    "    merged_rmse = root_mean_squared_error(y, merged_preds)\n",
    "    ensemble_rmses.append(merged_rmse)\n",
    "\n",
    "    print(merged_rmse)\n",
    "\n",
    "print('\\nMean RMSE:', np.mean(ensemble_rmses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
